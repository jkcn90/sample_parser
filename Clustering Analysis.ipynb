{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file_path = \"data/sample_conversations.json\"\n",
    "\n",
    "with open(data_file_path) as data_file:\n",
    "    raw_data = json.load(data_file)\n",
    "    \n",
    "messages = [message['Text'] for datum in raw_data['Issues'] for message in datum['Messages']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 22264, n_features: 8480\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), stop_words='english',\n",
    "                             max_df=0.008, min_df=0.0001)\n",
    "X = vectorizer.fit_transform(messages)\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n_components = 5000\n",
    "\n",
    "#svd = TruncatedSVD(n_components)\n",
    "#lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "#X = lsa.fit_transform(X)\n",
    "#explained_variance = svd.explained_variance_ratio_.sum()\n",
    "#print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0: john sorry hear hi john sorry john sorry hi john john hear account hacked hear account sorry hear account account hacked hacked\n",
      "Cluster 1: aspen truly 7163522001 course pretty court truly sorry 10p expensive help problem\n",
      "Cluster 2: awesome awesome day great awesome day great awesome king ok great awesome awesome help stephen king stephen like great\n",
      "Cluster 3: ve pulled account account payment march pulled account payment ve pulled account payment march 1st declined payment march 1st payment march 1st declined march 1st\n",
      "Cluster 4: needed uou needed help thank help thank needed help thank help zipcode great let service great let quickly great let pull\n",
      "Cluster 5: hope problem great problem great day fixing doesn happen finally soon ok hope hope help unacceptable\n",
      "Cluster 6: computer log account leave remember log verify great news service great news provide great hear great ordered\n",
      "Cluster 7: welcom idea andrew va yay yes home ll thanks 464 disregard 5185982456\n",
      "Cluster 8: bye zipcode great ll great like great let service great let quickly great let pull great let know great let insert great moment insert\n",
      "Cluster 9: ok thanks appreciate thanks ve ve customer ve customer years customer years years hopefully thanks appreciate won\n",
      "Cluster 10: absolutely yes absolutely zipcode great let insert great let service great let quickly great let pull great let know great let booked great ll\n",
      "Cluster 11: welcome great day welcome great zipcode great moment great like great let service great let quickly great let pull great let know great let insert\n",
      "Cluster 12: yep correct zipcode great let insert great let service great let quickly great let pull great let know great let booked great ll\n",
      "Cluster 13: assist today problem assist problem assist today happy assist today hi richard happy richard happy hi marie happy marie happy hi marie sam\n",
      "Cluster 14: let try zipcode great let service great let quickly great let pull great let know great let insert great let booked great let great ll\n",
      "Cluster 15: don worry sorry don don hear purchases don offer don offer refunds remember offer refunds don need\n",
      "Cluster 16: look account happy look account look account number happy look issues having minute going look issues having hello happy look\n",
      "Cluster 17: thank great day thank great enjoy new service new service enjoy new day enjoy great day enjoy enjoy great installation great just\n",
      "Cluster 18: twice charged twice charged concert tickets concert ordered tickets bought tickets bought noticed charged twice noticed charged\n",
      "Cluster 19: good rest day good rest great good rest day rest great good day good day patricia great let pull great let know\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 3000\n",
    "\n",
    "km = MiniBatchKMeans(n_clusters=n_clusters, n_init=1, init_size=10000, batch_size=5000)\n",
    "km.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(min(n_clusters, 20)):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That is strange, it seems the signal does not connect passed the exchange.',\n",
       " 'Whenever i try to connect, I do make sure that both my chromecast and my nexus are housed on the same wifi network which i made sure is relayed through a stronger buffalo router. But everytime i play a movie over the network attached storage, it just disconnects',\n",
       " 'I am unable to consistently connect to the internet',\n",
       " 'It seem the connect strenght has increased from our end',\n",
       " 'OK I have your modems status in front of me. I see that you are syncing with the exchange at the expected speed. I do however notice you have 10 devices connect currently?',\n",
       " \"Hello, I noticed that my phone service recently stopped. I'm able to connect to wifi just fine but whenever I use 3G anything that uses internet just hangs and fails to load. Can you help me with this problem?\",\n",
       " 'I can use wifi but phone service is dead',\n",
       " 'Hi my cell reception is not picking up. I have wifi for now but have a lot to do and need to see what the problem is',\n",
       " 'Hello, I just noticed that the service for my phone is not working. I am able to use wifi but nothing loads and I am unable to send any texts when I am not on wifi. Can you help me?',\n",
       " 'Hello, I just noticed that my service for my phone is not working anymore. My wifi works just fine, but nothing loads when I am not on wifi. Can you help me with this problem?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_predictions = km.predict(X)\n",
    "\n",
    "test_sentence = vectorizer.transform(['wifi help'])\n",
    "#test_sentence = lsa.transform(test_sentence)\n",
    "\n",
    "test_sentence_prediction = km.predict(test_sentence)\n",
    "\n",
    "similar_messages = [message for i, message in enumerate(messages)\n",
    "                    if message_predictions[i] == test_sentence_prediction]\n",
    "similar_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#labels = km.labels_\n",
    "#metrics.silhouette_score(X, labels, metric='euclidean')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
